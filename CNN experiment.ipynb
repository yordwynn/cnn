{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN для классификации поз\n",
    "\n",
    "Цель данного эксперимента - оценить точность классификации позы человека с помощью CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка\n",
    "\n",
    "В текущем блоке происходит загрузка обучающей выборки. Сейчас для теста используется выборка CFAR-10. Ее в последствии нужно будет заменить на MPII, но для начала можно запустить сеть на CFAR-10 и убедиться, что все работет.\n",
    "\n",
    "Также потребуется установить Pytorch. Инструкция по установке здесь: https://pytorch.org/get-started/locally/#anaconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка выборки. После того, как начнете работать с MPII, этот код будет заменен на загрузку соответствующей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cs231n/datasets\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cs231n/datasets\\cifar-10-python.tar.gz to ./cs231n/datasets\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000\n",
    "\n",
    "# The torchvision.transforms package provides tools for preprocessing data\n",
    "# and for performing data augmentation; here we set up a transform to\n",
    "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
    "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
    "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
    "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
    "# training set into train and val sets by passing a Sampler object to the\n",
    "# DataLoader telling how it should sample from the underlying Dataset.\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "Можно использовать для рассчетов GPU, задавая значение флага `USE_GPU`. Если компьютер не поддерживает CUDA, `torch.cuda.is_available()` вернет False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка точности "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Заменить эту проверку точности на проверку точности средствами PyTorch\n",
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Заменить это обучение на обучение средствами PyTorch\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN для классификации поз\n",
    "\n",
    "Этот блок пояснений я оставил, потому что там есть полезная для вас информация.\n",
    "\n",
    "Useful links\n",
    "\n",
    "* Layers in torch.nn package: http://pytorch.org/docs/stable/nn.html\n",
    "* Activations: http://pytorch.org/docs/stable/nn.html#non-linear-activations\n",
    "* Loss functions: http://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "* Optimizers: http://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "\n",
    "### Things you might try:\n",
    "- **Filter size**: Above we used 5x5; would smaller filters be more efficient?\n",
    "- **Number of filters**: Above we used 32 filters. Do more or fewer do better?\n",
    "- **Pooling vs Strided Convolution**: Do you use max pooling or just stride convolutions?\n",
    "- **Batch normalization**: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?\n",
    "- **Network architecture**: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:\n",
    "    - [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "- **Global Average Pooling**: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in [Google's Inception Network](https://arxiv.org/abs/1512.00567) (See Table 1 for their architecture).\n",
    "- **Regularization**: Add l2 weight regularization, or perhaps use Dropout.\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and other hyperparameters. When doing this there are a couple important things to keep in mind:\n",
    "\n",
    "- If the parameters are working well, you should see improvement within a few hundred iterations\n",
    "- Remember the coarse-to-fine approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n",
    "- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
    "- You should use the validation set for hyperparameter search, and save your test set for evaluating your architecture on the best parameters as selected by the validation set.\n",
    "\n",
    "### Going above and beyond\n",
    "If you are feeling adventurous there are many other features you can implement to try and improve your performance. You are **not required** to implement any of these, but don't miss the fun if you have time!\n",
    "\n",
    "- Alternative optimizers: you can try Adam, Adagrad, RMSprop, etc.\n",
    "- Alternative activation functions such as leaky ReLU, parametric ReLU, ELU, or MaxOut.\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- New Architectures\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) where the input from the previous layer is added to the output.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) where inputs into previous layers are concatenated together.\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.6093\n",
      "Checking accuracy on validation set\n",
      "Got 128 / 1000 correct (12.80)\n",
      "\n",
      "Iteration 100, loss = 1.3076\n",
      "Checking accuracy on validation set\n",
      "Got 521 / 1000 correct (52.10)\n",
      "\n",
      "Iteration 200, loss = 1.1626\n",
      "Checking accuracy on validation set\n",
      "Got 596 / 1000 correct (59.60)\n",
      "\n",
      "Iteration 300, loss = 1.0553\n",
      "Checking accuracy on validation set\n",
      "Got 610 / 1000 correct (61.00)\n",
      "\n",
      "Iteration 400, loss = 1.1296\n",
      "Checking accuracy on validation set\n",
      "Got 664 / 1000 correct (66.40)\n",
      "\n",
      "Iteration 500, loss = 1.0679\n",
      "Checking accuracy on validation set\n",
      "Got 650 / 1000 correct (65.00)\n",
      "\n",
      "Iteration 600, loss = 1.0168\n",
      "Checking accuracy on validation set\n",
      "Got 683 / 1000 correct (68.30)\n",
      "\n",
      "Iteration 700, loss = 0.9503\n",
      "Checking accuracy on validation set\n",
      "Got 694 / 1000 correct (69.40)\n",
      "\n",
      "Iteration 0, loss = 0.9781\n",
      "Checking accuracy on validation set\n",
      "Got 704 / 1000 correct (70.40)\n",
      "\n",
      "Iteration 100, loss = 1.0238\n",
      "Checking accuracy on validation set\n",
      "Got 717 / 1000 correct (71.70)\n",
      "\n",
      "Iteration 200, loss = 0.6762\n",
      "Checking accuracy on validation set\n",
      "Got 713 / 1000 correct (71.30)\n",
      "\n",
      "Iteration 300, loss = 0.8530\n",
      "Checking accuracy on validation set\n",
      "Got 705 / 1000 correct (70.50)\n",
      "\n",
      "Iteration 400, loss = 0.9992\n",
      "Checking accuracy on validation set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "\n",
      "Iteration 500, loss = 0.6645\n",
      "Checking accuracy on validation set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "\n",
      "Iteration 600, loss = 0.5536\n",
      "Checking accuracy on validation set\n",
      "Got 763 / 1000 correct (76.30)\n",
      "\n",
      "Iteration 700, loss = 0.8723\n",
      "Checking accuracy on validation set\n",
      "Got 755 / 1000 correct (75.50)\n",
      "\n",
      "Iteration 0, loss = 0.7326\n",
      "Checking accuracy on validation set\n",
      "Got 736 / 1000 correct (73.60)\n",
      "\n",
      "Iteration 100, loss = 0.3533\n",
      "Checking accuracy on validation set\n",
      "Got 737 / 1000 correct (73.70)\n",
      "\n",
      "Iteration 200, loss = 0.6843\n",
      "Checking accuracy on validation set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "\n",
      "Iteration 300, loss = 0.5415\n",
      "Checking accuracy on validation set\n",
      "Got 740 / 1000 correct (74.00)\n",
      "\n",
      "Iteration 400, loss = 0.7273\n",
      "Checking accuracy on validation set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "\n",
      "Iteration 500, loss = 0.6446\n",
      "Checking accuracy on validation set\n",
      "Got 751 / 1000 correct (75.10)\n",
      "\n",
      "Iteration 600, loss = 0.6851\n",
      "Checking accuracy on validation set\n",
      "Got 759 / 1000 correct (75.90)\n",
      "\n",
      "Iteration 700, loss = 0.7219\n",
      "Checking accuracy on validation set\n",
      "Got 781 / 1000 correct (78.10)\n",
      "\n",
      "Iteration 0, loss = 0.4775\n",
      "Checking accuracy on validation set\n",
      "Got 750 / 1000 correct (75.00)\n",
      "\n",
      "Iteration 100, loss = 0.4461\n",
      "Checking accuracy on validation set\n",
      "Got 775 / 1000 correct (77.50)\n",
      "\n",
      "Iteration 200, loss = 0.3982\n",
      "Checking accuracy on validation set\n",
      "Got 745 / 1000 correct (74.50)\n",
      "\n",
      "Iteration 300, loss = 0.3306\n",
      "Checking accuracy on validation set\n",
      "Got 779 / 1000 correct (77.90)\n",
      "\n",
      "Iteration 400, loss = 0.3819\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "\n",
      "Iteration 500, loss = 0.2533\n",
      "Checking accuracy on validation set\n",
      "Got 768 / 1000 correct (76.80)\n",
      "\n",
      "Iteration 600, loss = 0.3705\n",
      "Checking accuracy on validation set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "\n",
      "Iteration 700, loss = 0.4376\n",
      "Checking accuracy on validation set\n",
      "Got 767 / 1000 correct (76.70)\n",
      "\n",
      "Iteration 0, loss = 0.3038\n",
      "Checking accuracy on validation set\n",
      "Got 773 / 1000 correct (77.30)\n",
      "\n",
      "Iteration 100, loss = 0.2787\n",
      "Checking accuracy on validation set\n",
      "Got 789 / 1000 correct (78.90)\n",
      "\n",
      "Iteration 200, loss = 0.2075\n",
      "Checking accuracy on validation set\n",
      "Got 774 / 1000 correct (77.40)\n",
      "\n",
      "Iteration 300, loss = 0.4042\n",
      "Checking accuracy on validation set\n",
      "Got 790 / 1000 correct (79.00)\n",
      "\n",
      "Iteration 400, loss = 0.4575\n",
      "Checking accuracy on validation set\n",
      "Got 772 / 1000 correct (77.20)\n",
      "\n",
      "Iteration 500, loss = 0.3285\n",
      "Checking accuracy on validation set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "\n",
      "Iteration 600, loss = 0.3618\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "\n",
      "Iteration 700, loss = 0.3037\n",
      "Checking accuracy on validation set\n",
      "Got 799 / 1000 correct (79.90)\n",
      "\n",
      "Iteration 0, loss = 0.1377\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "\n",
      "Iteration 100, loss = 0.1790\n",
      "Checking accuracy on validation set\n",
      "Got 798 / 1000 correct (79.80)\n",
      "\n",
      "Iteration 200, loss = 0.3045\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "\n",
      "Iteration 300, loss = 0.1643\n",
      "Checking accuracy on validation set\n",
      "Got 771 / 1000 correct (77.10)\n",
      "\n",
      "Iteration 400, loss = 0.3625\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "\n",
      "Iteration 500, loss = 0.2840\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "\n",
      "Iteration 600, loss = 0.1928\n",
      "Checking accuracy on validation set\n",
      "Got 810 / 1000 correct (81.00)\n",
      "\n",
      "Iteration 700, loss = 0.2930\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "\n",
      "Iteration 0, loss = 0.1994\n",
      "Checking accuracy on validation set\n",
      "Got 781 / 1000 correct (78.10)\n",
      "\n",
      "Iteration 100, loss = 0.1444\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "\n",
      "Iteration 200, loss = 0.1622\n",
      "Checking accuracy on validation set\n",
      "Got 783 / 1000 correct (78.30)\n",
      "\n",
      "Iteration 300, loss = 0.1103\n",
      "Checking accuracy on validation set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "\n",
      "Iteration 400, loss = 0.2394\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "\n",
      "Iteration 500, loss = 0.1620\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60)\n",
      "\n",
      "Iteration 600, loss = 0.1871\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "\n",
      "Iteration 700, loss = 0.0869\n",
      "Checking accuracy on validation set\n",
      "Got 784 / 1000 correct (78.40)\n",
      "\n",
      "Iteration 0, loss = 0.1313\n",
      "Checking accuracy on validation set\n",
      "Got 805 / 1000 correct (80.50)\n",
      "\n",
      "Iteration 100, loss = 0.2102\n",
      "Checking accuracy on validation set\n",
      "Got 793 / 1000 correct (79.30)\n",
      "\n",
      "Iteration 200, loss = 0.2277\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "\n",
      "Iteration 300, loss = 0.1309\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "\n",
      "Iteration 400, loss = 0.0682\n",
      "Checking accuracy on validation set\n",
      "Got 797 / 1000 correct (79.70)\n",
      "\n",
      "Iteration 500, loss = 0.2411\n",
      "Checking accuracy on validation set\n",
      "Got 800 / 1000 correct (80.00)\n",
      "\n",
      "Iteration 600, loss = 0.1294\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "\n",
      "Iteration 700, loss = 0.1337\n",
      "Checking accuracy on validation set\n",
      "Got 788 / 1000 correct (78.80)\n",
      "\n",
      "Iteration 0, loss = 0.0643\n",
      "Checking accuracy on validation set\n",
      "Got 795 / 1000 correct (79.50)\n",
      "\n",
      "Iteration 100, loss = 0.0701\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "\n",
      "Iteration 200, loss = 0.0526\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "\n",
      "Iteration 300, loss = 0.1046\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60)\n",
      "\n",
      "Iteration 400, loss = 0.0646\n",
      "Checking accuracy on validation set\n",
      "Got 796 / 1000 correct (79.60)\n",
      "\n",
      "Iteration 500, loss = 0.1042\n",
      "Checking accuracy on validation set\n",
      "Got 807 / 1000 correct (80.70)\n",
      "\n",
      "Iteration 600, loss = 0.1184\n",
      "Checking accuracy on validation set\n",
      "Got 803 / 1000 correct (80.30)\n",
      "\n",
      "Iteration 700, loss = 0.0965\n",
      "Checking accuracy on validation set\n",
      "Got 792 / 1000 correct (79.20)\n",
      "\n",
      "Iteration 0, loss = 0.0678\n",
      "Checking accuracy on validation set\n",
      "Got 787 / 1000 correct (78.70)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9f0a03f66127>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Точность должна быть больше 70%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtrain_part34\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-ec4f30de8284>\u001b[0m in \u001b[0;36mtrain_part34\u001b[1;34m(model, optimizer, epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# put model to training mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# move to device, e.g. GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F  # useful stateless functions\n",
    "from models.convnet import ConvNet\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "#[conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "\n",
    "im_size = (32, 32, 3)\n",
    "conv_params = [(256, 3, 2), (256, 3, 2)]\n",
    "linear_params = [64, 10]\n",
    "learning_rate = 1e-2\n",
    "    \n",
    "model = ConvNet(im_size, conv_params, linear_params)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Точность должна быть больше 70%\n",
    "train_part34(model, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set -- run this only once\n",
    "\n",
    "Now that we've gotten a result we're happy with, we test our final model on the test set (which you should store in best_model). Think about how this compares to your validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model\n",
    "check_accuracy_part34(loader_test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
